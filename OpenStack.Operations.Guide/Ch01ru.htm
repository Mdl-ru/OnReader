<html>
<head>
   <link rel="icon" href="/i/MdlLogo.gif" type="image/gif">
   <title>Глава 1. Инициализация и развертывание. Руководство по эксплуатации OpenStack.</title>
   <meta name="Keywords" content="OpenStack, Cloud computing, Swift, RESTful, Object Storage, Ceph, CORS, CNAME lookup, Domain remap, Health check, Rate limiting, Bulk delete, Container qoutas, account qoutas, TempURL, Static Web, Form post, recon, Swift origin server, Bulk archive auto-extraction">
   <meta name="Description" content="Глава 1. Инициализация и развертывание. Руководство по эксплуатации OpenStack.">
   <meta name="Robots" content="INDEX, FOLLOW">
   <meta name="Author" content="Module-Projects,Ltd">
   <meta name="Copyright" content="Copyright 1998..2014 Module-Projects,Ltd">
   <meta http-equiv="Pragma" content="no-cache">
<script language="javascript" src="/css/v.0/mdlcss.js"></script>
<style type="text/css" media="screen, print">@import url("i/global-20140610.css");</style>
<script language="javascript" src="http://www.mdl.ru/usd.js"></script>
	<script language="javascript" src="http://www.mdl.ru/js/common.js"></script>
	<script language="javascript" src="http://www.mdl.ru/Solutions/ABC.js"></script>
</head>
<body>

<table class="bg_White" width="1024" align="center" valign="top" border="0" cellpadding="0" cellspacing="0"><tbody>
<tr>
<td>
<table width="100%" border="0" cellpadding="2" cellspacing=0 class="bg_White"><tbody>
<tr>
<td width="150" valign="top" align="center"><img src="http://www.mdl.ru/RMC9.jpg" border=0 /></td>
<td width="724" valign="bottom" align="center">
<a class="item-t" href="http://www.mdl.ru"><img src="http://www.mdl.ru/i/MdlBigLogo.gif" border="0"></a><br/>
<a class="item-t" href="http://www.mdl.ru">С 1991 года на компьютерном рынке России</a>
</td>
<td align="center" valign="bottom">
<a class="item-t" href="javascript:tocall()" onmouseover="this.href=mail"><img src="http://www.mdl.ru/i/9563499.gif" border="0" alt="e-mail" /><br/><br/>т.: 676 0965, 676 0396<br/>Москва, Сосинская ул. 43, <br/>м. Волгоградский проспект</a>
</td>
</tr>
<tr>
<td class="big_16y" colspan="3" align="center"><a href="index.htm">Руководство по эксплуатации OpenStack</a></td>
</tr>
<tr><td colspan="2">


<h2 align="right">ГЛАВА 1</h2>
<hr />
<h1 id="Chapter_01" align="right">Инициализация и развертывание</h1>

<em>Пользуйтесь переводом <strong>существенно переработанной и дополенной <a href="http://onreader.mdl.ru/openstack-ops/content/section_arch_provision.html">2й редакции</a></strong> (12-дек-2014),<br />
находящейся теперь и в режиме <a href="http://docs.openstack.org/openstack-ops/content/section_arch_provision.html">постоянно обновляемой документации</a> <br />
(последняя пока доступна только на англ.яз.).</em><br />
<p></p>

<p>Важной частью масштабируемости облака является объем усилий, требующихся для запуска вашего облака. 
Чтобы свести к минимуму эксплутационные расходы работы вашего облака, настройте и используйте 
автоматизированное развертывание и конфигурирование инфраструктуры.</p>

<p>Такая инфрасктруктура включает в себя системы для автоматической установки начальной конфигурации 
операционной системы, а впоследствии автоматически и централизованно координируют настройки всех служб, 
что одновременно уменьшает ручной труд и возможность ошибки.</p>

<h2 id="Ch0101">Автоматизированное развертывание</h2>
<p>Система автоматического развертывания устанавливает и настраивает операционные системы без вмешательства 
после абсолютно минимального объема ручного труда, включающего размещение в стойках, привязка MAC к IP, 
конфигурирование мощностей и тому подобного.
Обычные решения основываются на обертках (wrapper) на основе PXE загрузок и серверов TFTP для установки 
базовой операционной системы, передаваемой затем автоматизированным системам управления настройкой.</p>

<p>И Ubuntu, и Red Hat Linux содержат механизмы для настройки операционной системы, включающие установку 
предварительных начальных значений (preseed) и стартеры (kickstart), которые вы можете использовать после 
сетевой загрузки. 
Обычно они используются для начальной загрузки системы автоматической настройки.
Кроме того можно использовать подход на основе образов для развертывания операционной системы подобный 
systemimager. 
В виртуальной инфраструктуре вы можете использовать оба этих подхода, например, в случае,когда у вас 
раздельно работают VM ваших управляющих служб и физической инфраструктуры.</p>

<p>При создании плана развертывания сосредоточьтесь на нескольких жизненно важных областях, поскольку их 
очень трудно изменять после развертывания.</p>

<h3 id="Ch010101">Создание дисковых разделов и RAID</h3>

<p>В самом начале любой операционной системы находятся жесткие диски, на которые устанавливается ОС.</p>

<p>Вы должны выполнить следующую настройку на жестких дисках серверов:
</p>

<ul>
<li>Создание дисковых разделов
<li>Добавление в массив RAID
</ul>

<p>Простейший вариант заключается в использовании одного жесткого диска с двумя разделами:
</p>

<ul>
<li>Файловая система
<li>Пространство свопинга
</ul>

<p>В данной установке не используется RAID.</p>

<p><img src="i/Tip.jpg" alt="Tip" />Данный вариант не рекомендуется для практического применения, 
поскольку в случае отказа диска выходит из строя весь сервер. 
Вместо этого мы рекомендуем использовать более одного диска.
Количество дисков определяет какие типы массивов RAID могут быть построены.
</p>

<p>Мы рекомендуем вам один из следующих вариантов с несколькими дисками:</p>

<ul>
<li><srong>Вариант 1:</strong>
Единообразно разбиваем на разделы все диски горизонтальным образом, как показано на следующем рисунке:
<img src="i/Pic01-01.jpg" /><br />
В данном варианте вы можете назначить различные разделы различным массивам RAID.
Вы можете выделить раздел 1 первого и второго диска для зеркалированного раздела загрузки (/boot).
Вы можете сделать раздел 2 всех дисков зеркалированным корневым разделом (root).
Вы можете использовать 3й раздел всех дисков для  томов <code>cinder-volumes</code> разделов LVM работающих с массивом RAID 10.
<br />
Закончив с неиспользуемыми разделами, такими как 1й раздел  на третьем и четвертом дисках, вы могли 
бы максимально использовать дисковое пространство.
Однако, производительность ввода/вывода может испытывать проблемы при использовании всех дисков для
всех задач.

<li><strong>Вариант 2:</strong>
Добавьте все необработанные (raw) диски в один большой RAID массив на аппаратной или программной основе. 
Вы можете поделить этот большой массив на области загрузки, корня, свопинга и LVM.
Данный вариант прост в реализации и использует все разделы. 
Однако может пострадать дисковый ввод/вывод.

<li><strong>Вариант 3:</strong>
Выделите диски целиком  определенным разделам. 
Например, вы можете выделить один и два диска целиком для разделов загрузки, корня и свопинга под 
зеркалированный RAID 1. 
Затем выделите целиком диски 3 и 4 для раздела LVM, также под зеркалированным RAID 1. 
Дисковый ввод/вывод должен быть лучше, поскольку ввод/вывод сосредоточен на выделенных задачах. 
Однако, раздел LVM будет много меньшим.

<li><strong><em>Вариант 4,</em></strong>
<em>Примечание переводчика</em>: вы можете воспользоваться сетевой файловой системой при наличии достаточных (в отношении пропускной способности и латентности) средств коммутации.
Это может быть как аппаратно реализованная SAN, так и программно настраиваемые СХД.
В первом случае, как правило, для интерфейса используются протоколы SCSI/ Fibre Channel.
В последнем случае можно воспользоваться как коммерческим, так и открытым ПО (подробнее: 
<a href="http://www.mdl.ru/Solutions/Put.htm?Nme=GPFS">http://www.mdl.ru/Solutions/Put.htm?Nme=GPFS</a>, 
<a href="http://www.mdl.ru/Solutions/Put.htm?Nme=Storage">http://www.mdl.ru/Solutions/Put.htm?Nme=Storage</a>).
<br />В данном случае задачи оптимизации использования пространства и пропускной способности будут 
решать средства самой сетевой файловой системы.
</ul>

<p>Как и в случае большинства вариантов архитектуры, правильный ответ зависит от вашей среды.</p>

<h2 id="Ch010102">Настройка сети</h2>
<p>Конфигурирование сети является очень большим разделом, который охватывает несколько глав данной книги.
На текущий момент убедитесь, что ваши сервера могут выполнять PXE загрузку и успешно 
взаимодействуют с развертываемым сервером.</p>

<p>Например, обычно вы не можете настраивать сетевые адаптеры для VLAN при PXE загрузке. 
Кроме этого, как правило, вы не можете выполнять PXE загрузку при связанных сетевых адаптерах.
Если вы работаете по такому сценарию, рассмотрите возможность использования простого 1 GB коммутатора 
в частной локальной сети, в которой работает ваше облако.</p>

<h3 id="Ch0102">Автоматизация настройки</h3>

<p>Целью автоматического управления настройкой является установление и поддержание согласованности 
системы без вмешательства оператора.
 Вы хотите поддерживать согласованность вашего развертывания. следовательно вы можете иметь подобное 
 облако каждый раз, повторяя операции.
 Надлежащее использование инструментария управления автоматической настройкой гарантирует, что компоненты 
 облачных систем находятся в определенном состоянии, помимо упрощения развертывания и распространения 
 изменения конфигурации.</p>

<p>Эти средства также позволяют тестировать и откатывать назад изменения, поскольку они являются 
полностью повторяемыми. 
Все удобно, в данной области сообществом OpenStack был выполнен большой объем работ.
Инструмент управления конфигурациями – Puppet – даже предоставляет служебные модули для OpenStack.</p>

<p>Неотъемлемой частью системы управления настройками являются сами управляемые ею элементы.
Вы должны тщательно проанализировать все элементы, которыми вы хотите - или нет управлять автоматически.
</p>

<h2 id="Ch0103">Удаленное управление</h2>

<p>По нашему опыту, большинство операторов не сидят в непосредственной близости от работающих в 
облаке серверов, а также многие из них лишены удовольствия посещать центры данных.
OpenStack должен быть целиком настраиваемым удаленно, однако иногда не все идет по плану.</p>

<p>При подобных обстоятельствах будет благом иметь зоны доступа к компонентам работающих узлов OpenStack.
Стандартом де- факто здесь является протокол IPMI, и для достижения целей центров данных без 
персонала настоятельно рекомендуется приобретение такого оборудования.
</p>
<p>Кроме того, также уделите внимание удаленному управлению питанием.
Хотя IPMI обычно управляет состоянием питания, наличие удаленного доступа к блоку распределения 
питания (PDU), к которому подключен сервер может действительно оказаться полезным для случаев, 
когда все кажется заклиненным.
</p>

<table width="100%" border="0" cellpadding="2" cellspacing=0 class="bg_White"><tbody><tr>
 <td align="left"><a href="Preface.htm">Предисловие</a></td>
 <td align="center"><a href="index.htm">Оглавление</a></td>
 <td align="right"><a href="Ch02ru.htm">Глава 2</a></td>
</tr><tr><td colspan="3" style="border-bottom: thin solid;">&nbsp;</tr>
<tr><td colspan="2" valign="top">Перевод: Copyright ©&nbsp;2014 &nbsp;<img src="/i/mdl-reg.jpg" widht="35" height="12" style="border-style: none;">.<br>
All rights reserved.<br />
Ссылки обязательны (Refs and links obligatory).</td>
<td valign="top" align="right"><em><a href="http://www.mdl.ru">http://www.mdl.ru</a></em></td></tr>
</tbody></table>


<td align="right" valign="top">
<script language="javascript">
WriteABC('GPFS');
//--></script>
</tr>
</tbody></table>
</tbody></table>
</body>
</html>
